{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Mix-of-Show-colab/blob/main/Mix_of_Show_fused_single_anime_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Mix-of-Show\n",
        "%cd /content/Mix-of-Show\n",
        "\n",
        "!pip install -q diffusers==0.20.2 transformers accelerate einops omegaconf\n",
        "\n",
        "!git clone https://huggingface.co/ckpt/MoS-hina-kario-tezuka-anythingv4\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "from mixofshow.pipelines.pipeline_edlora import EDLoRAPipeline\n",
        "pretrained_model_path = '/content/Mix-of-Show/MoS-hina-kario-tezuka-anythingv4'\n",
        "enable_edlora = True  # True for edlora, False for lora\n",
        "pipe = EDLoRAPipeline.from_pretrained(pretrained_model_path, scheduler=DPMSolverMultistepScheduler.from_pretrained(pretrained_model_path, subfolder='scheduler'), torch_dtype=torch.float16).to('cuda')\n",
        "with open(f'{pretrained_model_path}/new_concept_cfg.json', 'r') as fr:\n",
        "    new_concept_cfg = json.load(fr)\n",
        "pipe.set_new_concept_cfg(new_concept_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOK = '<hina1> <hina2>'  # the TOK is the concept name when training lora/edlora\n",
        "prompt = f'a {TOK} in front of mount fuji'\n",
        "negative_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'\n",
        "image = pipe(prompt, negative_prompt=negative_prompt, height=1024, width=512, num_inference_steps=50, generator=torch.Generator('cuda'), guidance_scale=7.5).images[0]\n",
        "image.save(f'res.jpg')\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
