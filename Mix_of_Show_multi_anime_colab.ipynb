{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Mix-of-Show-colab/blob/main/Mix_of_Show_multi_anime_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Mix-of-Show\n",
        "%cd /content/Mix-of-Show\n",
        "\n",
        "!pip install -q diffusers==0.20.2 transformers accelerate einops omegaconf\n",
        "\n",
        "# !mkdir -p /content/Mix-of-Show/models/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500\n",
        "# !wget https://huggingface.co/camenduru/Mix-of-Show/resolve/main/single_concept_model/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500/models/edlora_model-latest.pth?download=true -O /content/Mix-of-Show/models/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500/edlora_model-latest.pth\n",
        "# !mkdir -p /content/Mix-of-Show/models/1002_1_EDLoRA_kaori_Anyv4_B4_Repeat500\n",
        "# !wget https://huggingface.co/camenduru/Mix-of-Show/resolve/main/single_concept_model/1002_1_EDLoRA_kaori_Anyv4_B4_Repeat500/models/edlora_model-latest.pth?download=true -O /content/Mix-of-Show/models/1002_1_EDLoRA_kaori_Anyv4_B4_Repeat500/edlora_model-latest.pth\n",
        "# !mkdir -p /content/Mix-of-Show/models/1003_1_EDLoRA_tezuka_Anyv4_B4_Repeat500\n",
        "# !wget https://huggingface.co/camenduru/Mix-of-Show/resolve/main/single_concept_model/1003_1_EDLoRA_tezuka_Anyv4_B4_Repeat500/models/edlora_model-latest.pth?download=true -O /content/Mix-of-Show/models/1003_1_EDLoRA_tezuka_Anyv4_B4_Repeat500/edlora_model-latest.pth\n",
        "\n",
        "# !mkdir -p /content/Mix-of-Show/multi-concept\n",
        "\n",
        "# !python gradient_fusion.py \\\n",
        "#     --concept_cfg=\"/content/Mix-of-Show/datasets/data_cfgs/MixofShow/multi-concept/anime/hina+kario+tezuka_anythingv4.json\" \\\n",
        "#     --save_path=\"/content/Mix-of-Show/multi-concept\" \\\n",
        "#     --pretrained_models=\"xyn-ai/anything-v4.0\" \\\n",
        "#     --optimize_textenc_iters=500 \\\n",
        "#     --optimize_unet_iters=50\n",
        "\n",
        "import gdown\n",
        "gdown.download_folder('https://drive.google.com/drive/folders/1OEWohYb509FPMeJluxWjXnWNG_49MJ4d', quiet=True)\n",
        "\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "from mixofshow.pipelines.pipeline_edlora import EDLoRAPipeline\n",
        "pretrained_model_path = '/content/Mix-of-Show/hina+kario+tezuka_anythingv4/combined_model_base'\n",
        "enable_edlora = True  # True for edlora, False for lora\n",
        "pipe = EDLoRAPipeline.from_pretrained(pretrained_model_path, scheduler=DPMSolverMultistepScheduler.from_pretrained(pretrained_model_path, subfolder='scheduler'), torch_dtype=torch.float16).to('cuda')\n",
        "with open(f'{pretrained_model_path}/new_concept_cfg.json', 'r') as fr:\n",
        "    new_concept_cfg = json.load(fr)\n",
        "pipe.set_new_concept_cfg(new_concept_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOK = '<hina1> <hina2>'  # the TOK is the concept name when training lora/edlora\n",
        "prompt = f'a {TOK} in front of mount fuji'\n",
        "negative_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'\n",
        "image = pipe(prompt, negative_prompt=negative_prompt, height=1024, width=512, num_inference_steps=50, generator=torch.Generator('cuda'), guidance_scale=7.5).images[0]\n",
        "image.save(f'res.jpg')\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Mix-of-Show\n",
        "\n",
        "fused_model=\"/content/Mix-of-Show/hina+kario+tezuka_anythingv4/combined_model_base\"\n",
        "expdir=\"/content/Mix-of-Show/hina+kario+tezuka_anythingv4\"\n",
        "\n",
        "keypose_condition='/content/Mix-of-Show/datasets/validation_spatial_condition/multi-characters/anime_pose_2x/hina_tezuka_kario_2x.png'\n",
        "keypose_adaptor_weight=1.0\n",
        "sketch_condition=''\n",
        "sketch_adaptor_weight=1.0\n",
        "\n",
        "context_prompt='two girls and a boy are standing near a forest'\n",
        "context_neg_prompt='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'\n",
        "\n",
        "region1_prompt='[a <hina1> <hina2>, standing near a forest]'\n",
        "region1_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region1='[12, 36, 1024, 600]'\n",
        "\n",
        "region2_prompt='[a <tezuka1> <tezuka2>, standing near a forest]'\n",
        "region2_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region2='[18, 696, 1024, 1180]'\n",
        "\n",
        "region5_prompt='[a <kaori1> <kaori2>, standing near a forest]'\n",
        "region5_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region5='[142, 1259, 1024, 1956]'\n",
        "\n",
        "prompt_rewrite=f\"{region1_prompt}-*-{region1_neg_prompt}-*-{region1}|{region2_prompt}-*-{region2_neg_prompt}-*-{region2}|{region5_prompt}-*-{region5_neg_prompt}-*-{region5}\"\n",
        "\n",
        "print(prompt_rewrite)\n",
        "\n",
        "!python regionally_controlable_sampling.py \\\n",
        "  --pretrained_model=\"{fused_model}\" \\\n",
        "  --sketch_adaptor_weight=\"{sketch_adaptor_weight}\" \\\n",
        "  --sketch_condition=\"{sketch_condition}\" \\\n",
        "  --keypose_adaptor_weight=\"{keypose_adaptor_weight}\" \\\n",
        "  --keypose_condition=\"{keypose_condition}\" \\\n",
        "  --save_dir=\"{expdir}\" \\\n",
        "  --prompt=\"{context_prompt}\" \\\n",
        "  --negative_prompt=\"{context_neg_prompt}\" \\\n",
        "  --prompt_rewrite=\"{prompt_rewrite}\" \\\n",
        "  --suffix=\"baseline\" \\\n",
        "  --seed=19"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
