{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Mix-of-Show-colab/blob/main/Mix_of_Show_hina_colab.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Mix-of-Show\n",
        "%cd /content/Mix-of-Show\n",
        "\n",
        "!pip install -q diffusers==0.20.2 transformers accelerate einops omegaconf\n",
        "!pip install -q https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl\n",
        "\n",
        "!mkdir -p /content/Mix-of-Show/models/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500\n",
        "!wget https://huggingface.co/camenduru/Mix-of-Show/resolve/main/single_concept_model/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500/models/edlora_model-latest.pth?download=true -O /content/Mix-of-Show/models/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500/edlora_model-latest.pth\n",
        "\n",
        "import torch\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "from mixofshow.pipelines.pipeline_edlora import EDLoRAPipeline, StableDiffusionPipeline\n",
        "from mixofshow.utils.convert_edlora_to_diffusers import convert_edlora\n",
        "\n",
        "enable_edlora = True\n",
        "pipeclass = EDLoRAPipeline if enable_edlora else StableDiffusionPipeline\n",
        "pretrained_model_path = 'xyn-ai/anything-v4.0'\n",
        "scheduler = DPMSolverMultistepScheduler.from_pretrained(pretrained_model_path, subfolder='scheduler')\n",
        "pipe = pipeclass.from_pretrained(pretrained_model_path, scheduler=scheduler, torch_dtype=torch.float16).to('cuda')\n",
        "edlora_path = '/content/Mix-of-Show/models/1001_1_EDLoRA_hina_Anyv4_B4_Repeat500/edlora_model-latest.pth'\n",
        "pipe, new_concept_cfg = convert_edlora(pipe, torch.load(edlora_path), enable_edlora=enable_edlora, alpha=1.0)\n",
        "pipe.set_new_concept_cfg(new_concept_cfg)\n",
        "pipe.unet.eval()\n",
        "pipe.text_encoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOK = '<hina1> <hina2>'  # the TOK is the concept name when training lora/edlora\n",
        "prompt = f'a {TOK} in front of eiffel tower, 4K, high quality, high resolution'\n",
        "negative_prompt = 'longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'\n",
        "image = pipe(prompt, negative_prompt=negative_prompt, height=512, width=512, num_inference_steps=50, guidance_scale=7.5).images[0]\n",
        "image.save('res.jpg')\n",
        "image"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
