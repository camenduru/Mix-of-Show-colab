{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/Mix-of-Show-colab/blob/main/test.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b dev https://github.com/camenduru/Mix-of-Show\n",
        "%cd /content/Mix-of-Show\n",
        "\n",
        "!pip install -q diffusers==0.20.2 transformers accelerate einops omegaconf\n",
        "\n",
        "!git clone https://huggingface.co/ckpt/MoS-hina-kario-tezuka-anythingv4\n",
        "\n",
        "%cd /content/Mix-of-Show\n",
        "\n",
        "import argparse\n",
        "import hashlib\n",
        "import json\n",
        "import os.path\n",
        "\n",
        "import torch\n",
        "from diffusers import DPMSolverMultistepScheduler\n",
        "from diffusers.models import T2IAdapter\n",
        "from PIL import Image\n",
        "\n",
        "from mixofshow.pipelines.pipeline_regionally_t2iadapter import RegionallyT2IAdapterPipeline\n",
        "\n",
        "\n",
        "def sample_image(pipe,\n",
        "    input_prompt,\n",
        "    input_neg_prompt=None,\n",
        "    generator=None,\n",
        "    num_inference_steps=50,\n",
        "    guidance_scale=7.5,\n",
        "    sketch_adaptor_weight=1.0,\n",
        "    region_sketch_adaptor_weight='',\n",
        "    keypose_adaptor_weight=1.0,\n",
        "    region_keypose_adaptor_weight='',\n",
        "    **extra_kargs\n",
        "):\n",
        "\n",
        "    keypose_condition = extra_kargs.pop('keypose_condition')\n",
        "    if keypose_condition is not None:\n",
        "        keypose_adapter_input = [keypose_condition] * len(input_prompt)\n",
        "    else:\n",
        "        keypose_adapter_input = None\n",
        "\n",
        "    sketch_condition = extra_kargs.pop('sketch_condition')\n",
        "    if sketch_condition is not None:\n",
        "        sketch_adapter_input = [sketch_condition] * len(input_prompt)\n",
        "    else:\n",
        "        sketch_adapter_input = None\n",
        "\n",
        "    images = pipe(\n",
        "        prompt=input_prompt,\n",
        "        negative_prompt=input_neg_prompt,\n",
        "        keypose_adapter_input=keypose_adapter_input,\n",
        "        keypose_adaptor_weight=keypose_adaptor_weight,\n",
        "        region_keypose_adaptor_weight=region_keypose_adaptor_weight,\n",
        "        sketch_adapter_input=sketch_adapter_input,\n",
        "        sketch_adaptor_weight=sketch_adaptor_weight,\n",
        "        region_sketch_adaptor_weight=region_sketch_adaptor_weight,\n",
        "        generator=generator,\n",
        "        guidance_scale=guidance_scale,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        **extra_kargs).images\n",
        "    return images\n",
        "\n",
        "\n",
        "def build_model(pretrained_model, device):\n",
        "    pipe = RegionallyT2IAdapterPipeline.from_pretrained(pretrained_model, torch_dtype=torch.float16).to(device)\n",
        "    assert os.path.exists(os.path.join(pretrained_model, 'new_concept_cfg.json'))\n",
        "    with open(os.path.join(pretrained_model, 'new_concept_cfg.json'), 'r') as json_file:\n",
        "        new_concept_cfg = json.load(json_file)\n",
        "    pipe.set_new_concept_cfg(new_concept_cfg)\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_pretrained(pretrained_model, subfolder='scheduler')\n",
        "    pipe.keypose_adapter = T2IAdapter.from_pretrained('TencentARC/t2iadapter_openpose_sd14v1', torch_dtype=torch.float16).to(device)\n",
        "    pipe.sketch_adapter = T2IAdapter.from_pretrained('TencentARC/t2iadapter_sketch_sd14v1', torch_dtype=torch.float16).to(device)\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def prepare_text(prompt, region_prompts, height, width):\n",
        "    '''\n",
        "    Args:\n",
        "        prompt_entity: [subject1]-*-[attribute1]-*-[Location1]|[subject2]-*-[attribute2]-*-[Location2]|[global text]\n",
        "    Returns:\n",
        "        full_prompt: subject1, attribute1 and subject2, attribute2, global text\n",
        "        context_prompt: subject1 and subject2, global text\n",
        "        entity_collection: [(subject1, attribute1), Location1]\n",
        "    '''\n",
        "    region_collection = []\n",
        "\n",
        "    regions = region_prompts.split('|')\n",
        "\n",
        "    for region in regions:\n",
        "        if region == '':\n",
        "            break\n",
        "        prompt_region, neg_prompt_region, pos = region.split('-*-')\n",
        "        prompt_region = prompt_region.replace('[', '').replace(']', '')\n",
        "        neg_prompt_region = neg_prompt_region.replace('[', '').replace(']', '')\n",
        "        pos = eval(pos)\n",
        "        if len(pos) == 0:\n",
        "            pos = [0, 0, 1, 1]\n",
        "        else:\n",
        "            pos[0], pos[2] = pos[0] / height, pos[2] / height\n",
        "            pos[1], pos[3] = pos[1] / width, pos[3] / width\n",
        "\n",
        "        region_collection.append((prompt_region, neg_prompt_region, pos))\n",
        "    return (prompt, region_collection)\n",
        "\n",
        "pretrained_model=\"/content/Mix-of-Show/MoS-hina-kario-tezuka-anythingv4\"\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "pipe = build_model(pretrained_model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /content/Mix-of-Show\n",
        "\n",
        "expdir=\"/content/Mix-of-Show/hina+kario+tezuka_anythingv4\"\n",
        "\n",
        "keypose_condition='/content/Mix-of-Show/datasets/validation_spatial_condition/multi-characters/anime_pose_2x/hina_tezuka_kario_2x.png'\n",
        "keypose_adaptor_weight=1.0\n",
        "sketch_condition=''\n",
        "sketch_adaptor_weight=1.0\n",
        "\n",
        "context_prompt='two girls and a boy are standing in front of mount fuji'\n",
        "negative_prompt='longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality'\n",
        "\n",
        "region1_prompt='[a <hina1> <hina2>, standing in front of mount fuji]'\n",
        "region1_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region1='[12, 36, 1024, 600]'\n",
        "\n",
        "region2_prompt='[a <tezuka1> <tezuka2>, standing in front of mount fuji]'\n",
        "region2_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region2='[18, 696, 1024, 1180]'\n",
        "\n",
        "region5_prompt='[a <kaori1> <kaori2>, standing in front of mount fuji]'\n",
        "region5_neg_prompt=\"[${context_neg_prompt}]\"\n",
        "region5='[142, 1259, 1024, 1956]'\n",
        "\n",
        "prompt_rewrite=f\"{region1_prompt}-*-{region1_neg_prompt}-*-{region1}|{region2_prompt}-*-{region2_neg_prompt}-*-{region2}|{region5_prompt}-*-{region5_neg_prompt}-*-{region5}\"\n",
        "\n",
        "print(prompt_rewrite)\n",
        "\n",
        "if sketch_condition is not None and os.path.exists(sketch_condition):\n",
        "    sketch_condition = Image.open(sketch_condition).convert('L')\n",
        "    width_sketch, height_sketch = sketch_condition.size\n",
        "    print('use sketch condition')\n",
        "else:\n",
        "    sketch_condition, width_sketch, height_sketch = None, 0, 0\n",
        "    print('skip sketch condition')\n",
        "\n",
        "if keypose_condition is not None and os.path.exists(keypose_condition):\n",
        "    keypose_condition = Image.open(keypose_condition).convert('RGB')\n",
        "    width_pose, height_pose = keypose_condition.size\n",
        "    print('use pose condition')\n",
        "else:\n",
        "    keypose_condition, width_pose, height_pose = None, 0, 0\n",
        "    print('skip pose condition')\n",
        "\n",
        "if width_sketch != 0 and width_pose != 0:\n",
        "    assert width_sketch == width_pose and height_sketch == height_pose, 'conditions should be same size'\n",
        "width, height = max(width_pose, width_sketch), max(height_pose, height_sketch)\n",
        "\n",
        "kwargs = {\n",
        "    'sketch_condition': sketch_condition,\n",
        "    'keypose_condition': keypose_condition,\n",
        "    'height': height,\n",
        "    'width': width,\n",
        "}\n",
        "\n",
        "suffix='baseline'\n",
        "save_dir=expdir\n",
        "region_keypose_adaptor_weight = ''\n",
        "region_sketch_adaptor_weight = ''\n",
        "seed = 1\n",
        "prompt = 'photo of a toy'\n",
        "prompts = [prompt]\n",
        "prompts_rewrite = [prompt_rewrite]\n",
        "input_prompt = [prepare_text(p, p_w, height, width) for p, p_w in zip(prompts, prompts_rewrite)]\n",
        "save_prompt = input_prompt[0][0]\n",
        "\n",
        "image = sample_image(\n",
        "    pipe,\n",
        "    input_prompt=input_prompt,\n",
        "    input_neg_prompt=[negative_prompt] * len(input_prompt),\n",
        "    generator=torch.Generator(device).manual_seed(seed),\n",
        "    sketch_adaptor_weight=sketch_adaptor_weight,\n",
        "    region_sketch_adaptor_weight=region_sketch_adaptor_weight,\n",
        "    keypose_adaptor_weight=keypose_adaptor_weight,\n",
        "    region_keypose_adaptor_weight=region_keypose_adaptor_weight,\n",
        "    **kwargs)\n",
        "\n",
        "print(f'save to: {save_dir}')\n",
        "\n",
        "configs = [\n",
        "    f'pretrained_model: {pretrained_model}\\n',\n",
        "    f'context_prompt: {prompt}\\n', f'neg_context_prompt: {negative_prompt}\\n',\n",
        "    f'sketch_condition: {sketch_condition}\\n', f'sketch_adaptor_weight: {sketch_adaptor_weight}\\n',\n",
        "    f'region_sketch_adaptor_weight: {region_sketch_adaptor_weight}\\n',\n",
        "    f'keypose_condition: {keypose_condition}\\n', f'keypose_adaptor_weight: {keypose_adaptor_weight}\\n',\n",
        "    f'region_keypose_adaptor_weight: {region_keypose_adaptor_weight}\\n', f'random seed: {seed}\\n',\n",
        "    f'prompt_rewrite: {prompt_rewrite}\\n'\n",
        "]\n",
        "hash_code = hashlib.sha256(''.join(configs).encode('utf-8')).hexdigest()[:8]\n",
        "\n",
        "save_prompt = save_prompt.replace(' ', '_')\n",
        "save_name = f'{save_prompt}---{suffix}---{hash_code}.png'\n",
        "save_dir = os.path.join(save_dir, f'seed_{seed}')\n",
        "save_path = os.path.join(save_dir, save_name)\n",
        "save_config_path = os.path.join(save_dir, save_name.replace('.png', '.txt'))\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "image[0].save(os.path.join(save_dir, save_name))\n",
        "\n",
        "with open(save_config_path, 'w') as fw:\n",
        "    fw.writelines(configs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
